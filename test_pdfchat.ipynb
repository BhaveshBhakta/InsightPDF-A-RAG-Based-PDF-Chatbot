{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InsightPDF: A RAG-Based PDF Chatbot  \n",
    "> A chatbot that lets you ask questions about any PDF using Groq's LLaMA-3 and ChromaDB for smart retrieval and answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "import PyPDF2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma \n",
    "import chromadb \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import Document\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "llm = None\n",
    "vectorstore = None\n",
    "conversation_chain = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API setup\n",
    "\n",
    "def setup_groq_api():\n",
    "    llm = ChatGroq(\n",
    "        groq_api_key='gxxxx', # Replace with your Groq API key\n",
    "        model_name=\"llama-3.3-70b-versatile\",  \n",
    "        temperature=0.1,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Loading and Extracting text from PDF\n",
    "\n",
    "def load_pdf(pdf_path): \n",
    "    documents = []\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "\n",
    "            doc = Document(page_content=text, metadata={\"source\": pdf_path})\n",
    "            documents.append(doc)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PDF: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"PDF loaded successfully! Extracted {len(text)} characters\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Chroma vector store from documents\n",
    "\n",
    "def create_vectorstore(documents):\n",
    "    global vectorstore\n",
    "    print(\"Creating vector embeddings with Chroma...\")\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(chunks)} text chunks\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    # Defining a directory for persistent storage\n",
    "    persist_directory = \"./chroma_db\"\n",
    "    if not os.path.exists(persist_directory):\n",
    "        os.makedirs(persist_directory)\n",
    "\n",
    "    # Initializing a persistent Chroma client\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    collection_name = \"pdf_chatbot_collection\"\n",
    "\n",
    "    # Creating Chroma vector store. (If the collection exists, it will be loaded. Otherwise, a new one is created.)\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        chunks,\n",
    "        embeddings,\n",
    "        client=client,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "\n",
    "    print(\" Chroma vector store created successfully!\")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval chain setup\n",
    "\n",
    "def setup_conversation_chain(current_llm, current_vectorstore):\n",
    "    global conversation_chain\n",
    "    print(\"ðŸ”— Setting up conversation chain...\")\n",
    "\n",
    "    if current_llm is None or current_vectorstore is None:\n",
    "        print(\" LLM or Vectorstore not initialized. Please run setup_groq_api() and create_vectorstore() first.\")\n",
    "        return None\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True,\n",
    "        output_key=\"answer\"\n",
    "    )\n",
    "\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=current_llm,\n",
    "        retriever=current_vectorstore.as_retriever(search_kwargs={\"k\": 4}),\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    print(\"Conversation chain setup complete!\")\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the complete chatbot.\n",
    "\n",
    "def initialize_chatbot(pdf_path):\n",
    "    global llm, vectorstore, conversation_chain\n",
    "    print(\"Initializing PDF Chatbot...\")\n",
    "\n",
    "    # Step 1: Setup API\n",
    "    llm = setup_groq_api()\n",
    "    if llm is None:\n",
    "        print(\"Initialization failed: Groq API setup issue.\")\n",
    "        return False\n",
    "\n",
    "    # Step 2: Load PDF\n",
    "    documents = load_pdf(pdf_path)\n",
    "    if not documents:\n",
    "        print(\"Initialization failed: PDF loading issue.\")\n",
    "        return False\n",
    "\n",
    "    # Step 3: Create vector store\n",
    "    vectorstore = create_vectorstore(documents)\n",
    "    if vectorstore is None:\n",
    "        print(\"Initialization failed: Vector store creation issue.\")\n",
    "        return False\n",
    "\n",
    "    # Step 4: Setup chain\n",
    "    conversation_chain = setup_conversation_chain(llm, vectorstore)\n",
    "    if conversation_chain is None:\n",
    "        print(\"Initialization failed: Conversation chain setup issue.\")\n",
    "        return False\n",
    "\n",
    "    print(\"Chatbot initialized successfully!\")\n",
    "    print(\"You can now start chatting with your PDF!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat History\n",
    "\n",
    "def get_chat_history():\n",
    "    global conversation_chain\n",
    "    if conversation_chain is None or not conversation_chain.memory:\n",
    "        return \"No chat history available.\"\n",
    "\n",
    "    history = conversation_chain.memory.chat_memory.messages\n",
    "    formatted_history = \" **Chat History:**\\n\\n\"\n",
    "\n",
    "    for i, message in enumerate(history):\n",
    "        role = \"ðŸ§‘ User\" if message.type == \"human\" else \"ðŸ¤– Assistant\"\n",
    "        formatted_history += f\"{role}: {message.content}\\n\\n\"\n",
    "\n",
    "    return formatted_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_pdf(question):\n",
    "    global conversation_chain\n",
    "    if conversation_chain is None:\n",
    "        return \"Chatbot not initialized. Please run initialize_chatbot() first.\"\n",
    "\n",
    "    try:\n",
    "        response = conversation_chain({\"question\": question})\n",
    "\n",
    "        answer = response['answer']\n",
    "        source_docs = response.get('source_documents', [])\n",
    "\n",
    "        formatted_response = f\"ðŸ¤– **Answer:** {answer}\\n\\n\"\n",
    "\n",
    "        if source_docs:\n",
    "            formatted_response += \"**Sources:**\\n\"\n",
    "            for i, doc in enumerate(source_docs[:2], 1):\n",
    "                preview = doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content\n",
    "                source_info = doc.metadata.get(\"source\", \"Unknown Source\")\n",
    "                formatted_response += f\"{i}. From: `{source_info}`\\n   Content: `{preview}`\\n\\n\"\n",
    "\n",
    "        return formatted_response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during chat: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Usage\n",
    "\n",
    "def demo_usage():\n",
    "    print(\"PDF Chatbot Demo\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    pdf_path = input(\" Enter the path to your PDF file (e.g., my_document.pdf): \")\n",
    "\n",
    "    if initialize_chatbot(pdf_path):\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\" Chat Interface Ready!\")\n",
    "        print(\"Type 'quit' to exit, 'history' to see chat history\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        while True:\n",
    "            question = input(\"\\nðŸ§‘ You: \")\n",
    "\n",
    "            if question.lower() == 'quit':\n",
    "                print(\" Goodbye!\")\n",
    "                break\n",
    "            elif question.lower() == 'history':\n",
    "                print(get_chat_history())\n",
    "                continue\n",
    "\n",
    "            response = chat_with_pdf(question)\n",
    "            print(f\"\\n{response}\")\n",
    "    else:\n",
    "        print(\" Failed to initialize chatbot. Please check errors above.\")\n",
    "\n",
    "demo_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
